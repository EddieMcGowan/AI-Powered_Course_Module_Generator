{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c60fe-dc32-42be-b440-2df6b9c439bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65386a-ba24-4277-b430-ed5c97c81e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"vllm[cuda118]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5357823d-8cea-40b4-87ef-6105964ed5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.25.4-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "\u001b[33m  WARNING: The script pymupdf is installed in '/home/jupyter-wem220/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pymupdf-1.25.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28dc9d7f-8acd-47d7-a553-cfbac889a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "def extract_text_pymupdf(pdf_path):\n",
    "    \"\"\"Extracts text from a structured (non-scanned) PDF.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f185a30f-c0df-4b70-9011-67fc63076430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables_pdf(pdf_path):\n",
    "    \"\"\"Extracts tables from a PDF and converts them into DataFrames.\"\"\"\n",
    "    tables = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            table = page.extract_table()\n",
    "            if table:\n",
    "                df = pd.DataFrame(table[1:], columns=table[0])  # First row as headers\n",
    "                tables.append(df)\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80618659-a0f5-45ac-a2b6-6c5aa320747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_pdf(pdf_path, save_folder=\"images\"):\n",
    "    \"\"\"Extracts images from a PDF and saves them locally.\"\"\"\n",
    "    images = []\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            # Use pdfplumber's rendering for a rasterized image of the full page\n",
    "            img = page.to_image(resolution=150)\n",
    "            img_bytes = img.original\n",
    "            img_filename = f\"{save_folder}/pdf_page_{i+1}.png\"\n",
    "            with open(img_filename, \"wb\") as f:\n",
    "                f.write(img_bytes)\n",
    "            images.append(img_filename)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f042f34-ff4f-4b30-9ccb-7d0a5f4f778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_webpage(url):\n",
    "    \"\"\"Extracts text from an article webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    text = \"\\n\".join([p.get_text(strip=True) for p in soup.find_all(\"p\")])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a9b5a1-8035-4309-9e05-fb7ff1545dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables_webpage(url):\n",
    "    \"\"\"Extracts tables from a webpage and converts them into DataFrames.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    tables = []\n",
    "    for table in soup.find_all(\"table\"):\n",
    "        rows = []\n",
    "        for row in table.find_all(\"tr\"):\n",
    "            cells = [cell.get_text(strip=True) for cell in row.find_all([\"td\", \"th\"])]\n",
    "            rows.append(cells)\n",
    "        if rows:\n",
    "            df = pd.DataFrame(rows[1:], columns=rows[0])  # First row as headers\n",
    "            tables.append(df)\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95cbc462-81aa-44af-88bf-76af3c73d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_webpage(url, save_folder=\"images\"):\n",
    "    \"\"\"Extracts images from a webpage and saves them locally.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    images = []\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    for i, img in enumerate(soup.find_all(\"img\")):\n",
    "        img_url = img.get(\"src\")\n",
    "        if img_url and img_url.startswith((\"http\", \"//\")):\n",
    "            img_url = img_url if img_url.startswith(\"http\") else \"https:\" + img_url\n",
    "            try:\n",
    "                img_data = requests.get(img_url).content\n",
    "                img_filename = os.path.join(save_folder, f\"image_{i+1}.jpg\")\n",
    "                with open(img_filename, \"wb\") as f:\n",
    "                    f.write(img_data)\n",
    "                images.append(img_filename)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download {img_url}: {e}\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58592f16-25de-4acd-ae28-52ff867560ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(source):\n",
    "    \"\"\"Extracts text from PDF or web URL.\"\"\"\n",
    "    if source.endswith(\".pdf\"):\n",
    "        return extract_text_pymupdf(source)  # Extract from PDF\n",
    "    elif source.startswith(\"http\"):\n",
    "        return extract_text_webpage(source)  # Extract from web page\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Provide a PDF or URL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58d91d-ed42-4f30-9c84-57fd3b531fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables(source):\n",
    "    \"\"\"Extracts tables from a PDF or web URL and converts them into DataFrames.\"\"\"\n",
    "    if source.endswith(\".pdf\"):\n",
    "        return extract_tables_pdf(source)  # Extract from PDF\n",
    "    elif source.startswith(\"http\"):\n",
    "        return extract_tables_webpage(source)  # Extract from web page\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Provide a PDF or URL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2beb10e-109e-4283-b63e-be900e2cd5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(source, save_folder=\"images\"):\n",
    "    \"\"\"Extracts images from PDFs or web pages and saves them locally.\"\"\"\n",
    "    if source.endswith(\".pdf\"):\n",
    "        return extract_images_pdf(source, save_folder)  # Extract from PDF\n",
    "    elif source.startswith(\"http\"):\n",
    "        return extract_images_webpage(source, save_folder)  # Extract from web page\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Provide a PDF or URL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0954e48-734a-4609-9ad1-2ffc4b2fd09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def extract_all(sources):\n",
    "    \"\"\"Extracts text, tables, and images from multiple PDFs and web pages.\"\"\"\n",
    "    combined_text = []\n",
    "    combined_tables = []\n",
    "    combined_images = []\n",
    "    source_references = []  # Store source details\n",
    "\n",
    "    for source in sources:\n",
    "        text = extract_text(source)\n",
    "        tables = extract_tables(source)\n",
    "        images = extract_images(source)\n",
    "\n",
    "        combined_text.append(text)\n",
    "        combined_tables.extend(tables)\n",
    "        combined_images.extend(images)\n",
    "        source_references.append(source)\n",
    "\n",
    "    return combined_text, combined_tables, combined_images, source_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d31094-e81b-400f-8f92-6e64efe32a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def generate_lesson_from_extracted_data(sources):\n",
    "    \"\"\"Extracts data from multiple sources and generates an AI-powered lesson with embedded tables and image placeholders.\"\"\"\n",
    "\n",
    "    # Step 1: Extract content\n",
    "    all_texts, all_tables, all_images, all_sources = extract_all(sources)\n",
    "\n",
    "    # Step 2: Convert tables to Markdown\n",
    "    def table_to_markdown(tables):\n",
    "        markdown_tables = []\n",
    "        for df in tables:\n",
    "            markdown_tables.append(df.to_markdown(index=False))\n",
    "        return \"\\n\\n\".join(markdown_tables)\n",
    "    \n",
    "    tables_markdown = table_to_markdown(all_tables)\n",
    "\n",
    "    # Step 3: Prepare combined text (truncated if needed)\n",
    "    combined_text = \"\\n\\n\".join(all_texts)[:4000]  # Truncate to avoid token limits\n",
    "\n",
    "    # Step 4: Prepare image markdown placeholders\n",
    "    image_placeholders = \"\\n\".join([\n",
    "        f\"![image]({img})\" for img in all_images\n",
    "    ]) if all_images else \"No images extracted.\"\n",
    "\n",
    "    # Step 5: Construct the prompt\n",
    "    prompt = f\"\"\"\n",
    "You are an educational content generator. Your task is to create a structured lesson using the extracted text, tables, and images provided below.\n",
    "\n",
    "### Extracted Text:\n",
    "{combined_text}\n",
    "\n",
    "### Extracted Tables (Markdown Format):\n",
    "{tables_markdown}\n",
    "\n",
    "### Source Webpages & Documents:\n",
    "{', '.join(all_sources)}\n",
    "\n",
    "### Extracted Images:\n",
    "Use the following image files at appropriate points in your lesson. Include each one using Markdown syntax like: `![image](imageX.png)`.\n",
    "\n",
    "{image_placeholders}\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Instructions:\n",
    "- Integrate the **Markdown tables** into the lesson where they add value.\n",
    "- **Include each image** by referencing it at the most relevant point in the content (using the Markdown format).\n",
    "- Write a clear, engaging lesson with sections, subheadings, and explanations.\n",
    "- Briefly describe the images where included, to help learners understand their relevance.\n",
    "\n",
    "Begin generating the lesson below:\n",
    "\"\"\"\n",
    "\n",
    "    # Step 6: Load the AI model (adjust model name/device as needed)\n",
    "    generator = pipeline(\"text-generation\", model=\"meta-llama/Llama-2-7b-chat-hf\", device=\"cuda\")\n",
    "\n",
    "    # Step 7: Generate response\n",
    "    response = generator(prompt, max_length=2000, do_sample=True, temperature=0.7)\n",
    "\n",
    "    return response[0][\"generated_text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50372bb0-6439-473f-ba22-295cc79b8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### For testing the gen AI model to see capabilities\n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "llm = LLM(model=\"meta-llama/Llama-2-7b-chat-hf\")  # Make sure you have access to this model\n",
    "sampling_params = SamplingParams(temperature=0.7, max_tokens=500)\n",
    "\n",
    "prompt = \"Explain machine learning to a high school student.\"\n",
    "outputs = llm.generate([prompt], sampling_params)\n",
    "\n",
    "print(outputs[0].outputs[0].text)  # Print AI-generated response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b89fe3-2e82-4c62-ae68-3312627f3957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
